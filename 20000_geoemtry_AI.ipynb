{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1k_RKfJ9yRweqiAMzX_xn8JV20xrixP4N",
      "authorship_tag": "ABX9TyMR+1xtmyGfmGe4qPaNIRb+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashsom2008/richpanel_project/blob/main/20000_geoemtry_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxspWVnAvyNy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linking  G Colab with G Drive"
      ],
      "metadata": {
        "id": "4OofRluaxQkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF2ofdi6v8V_",
        "outputId": "d6088f69-e557-44c4-8f44-9a07d7840750"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIBTuL6tzp4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Library import and Images ka data generation"
      ],
      "metadata": {
        "id": "mWbA1gHwnu8X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bt3GVklbFtGW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rescaling using (Normalization 1./255)\n",
        "  ( as model is small and data is large may occur OVERFITTING issue )"
      ],
      "metadata": {
        "id": "ydc5xjq1vVVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = ImageDataGenerator(rescale =1./255)                                 # to make value between 0 to 1 we divide by 255 as greyscale image has value range 0 to 255\n",
        "validation = ImageDataGenerator(rescale = 1./255)\n"
      ],
      "metadata": {
        "id": "rsi_eQj_z--9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Validation ke liye data fetching"
      ],
      "metadata": {
        "id": "cnXeYd4HvwDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/dataset/train',\n",
        "                                          target_size = (227,227),                                   # images ko 227 * 227 ke format me laa rha hu\n",
        "                                          batch_size = 64,                                           # 64 images at a time aa rhi hai directory se\n",
        "                                          class_mode = \"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJYwLBpW0CRG",
        "outputId": "9582cf32-9c67-4a09-aae2-b41fb3e3d1a8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12040 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_dataset = validation.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/dataset/val',\n",
        "                                          target_size = (227,227),\n",
        "                                          batch_size = 64,\n",
        "                                          class_mode = \"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7iJXwK10F8i",
        "outputId": "74e2a13c-4976-482e-d1a9-006644180c59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4060 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TfhyfOvf1Yqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categories and classes formation"
      ],
      "metadata": {
        "id": "U_wWuGJFwkn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHRqP-6rQALZ",
        "outputId": "d17d0b04-84a3-4be4-d277-5edd2e70cb2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'circle': 0,\n",
              " 'kite': 1,\n",
              " 'parallelogram': 2,\n",
              " 'rectangle': 3,\n",
              " 'rhombus': 4,\n",
              " 'square': 5,\n",
              " 'trapezoid': 6,\n",
              " 'triangle': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_dataset.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model formation"
      ],
      "metadata": {
        "id": "_CaQaucywxTD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ctB_90YRQBVm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\",input_shape = (227,227,3)),tf.keras.layers.MaxPool2D(2,2),    # 3 colour chennel bta  rha h\n",
        "                                    #\n",
        "                                    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\"),\n",
        "                                    tf.keras.layers.MaxPool2D(2,2),\n",
        "                                    #\n",
        "                                    tf.keras.layers.Conv2D(64,(3,3),activation=\"relu\"),\n",
        "                                    tf.keras.layers.MaxPool2D(2,2),\n",
        "                                    #\n",
        "\n",
        "                                    ##\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    ##\n",
        "                                    tf.keras.layers.Dense(512,activation = \"relu\"),\n",
        "                                    ##\n",
        "                                    tf.keras.layers.Dense(8,activation = \"softmax\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL SUMMARY"
      ],
      "metadata": {
        "id": "739sATizw-iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPK0l8nV6At2",
        "outputId": "3aab1df2-4e43-4eb7-de7f-dfff83ec1e6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 225, 225, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 110, 110, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 55, 55, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 53, 53, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 43264)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               22151680  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 4104      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22179368 (84.61 MB)\n",
            "Trainable params: 22179368 (84.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL Compile( firnding errors) ho rha h"
      ],
      "metadata": {
        "id": "SPz4CBwy1joM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer = Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "88FARqeU8zye"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL  is being FITTING"
      ],
      "metadata": {
        "id": "NIlICyCv2aYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,\n",
        "          epochs=10,\n",
        "          validation_data=validation_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVjw3PbN2S8v",
        "outputId": "8196d43b-02f9-4442-ec26-731a166e413b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "189/189 [==============================] - 10946s 58s/step - loss: 0.7438 - accuracy: 0.7781 - val_loss: 0.1379 - val_accuracy: 0.9569\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 107s 567ms/step - loss: 0.0933 - accuracy: 0.9695 - val_loss: 0.0969 - val_accuracy: 0.9695\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 86s 455ms/step - loss: 0.0515 - accuracy: 0.9848 - val_loss: 0.0965 - val_accuracy: 0.9714\n",
            "Epoch 4/10\n",
            "189/189 [==============================] - 107s 565ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.1599 - val_accuracy: 0.9522\n",
            "Epoch 5/10\n",
            "189/189 [==============================] - 87s 461ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0560 - val_accuracy: 0.9825\n",
            "Epoch 6/10\n",
            "189/189 [==============================] - 88s 465ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0691 - val_accuracy: 0.9791\n",
            "Epoch 7/10\n",
            "189/189 [==============================] - 86s 457ms/step - loss: 0.0056 - accuracy: 0.9987 - val_loss: 0.0662 - val_accuracy: 0.9833\n",
            "Epoch 8/10\n",
            "189/189 [==============================] - 85s 452ms/step - loss: 0.0182 - accuracy: 0.9963 - val_loss: 0.0562 - val_accuracy: 0.9852\n",
            "Epoch 9/10\n",
            "189/189 [==============================] - 89s 473ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0565 - val_accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "189/189 [==============================] - 86s 455ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0546 - val_accuracy: 0.9847\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f680d5cb9a0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model saving"
      ],
      "metadata": {
        "id": "zIdWQxsxXHje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/species/,without augument with early64(0.00001).h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQGjSTe_XG09",
        "outputId": "feb6af1c-f9fd-4fe7-902c-840be8fd31c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fitting model import"
      ],
      "metadata": {
        "id": "sHWjdR9LXzWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "JYh1iXvaXw8m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# fitting model fetching"
      ],
      "metadata": {
        "id": "QsVjKBvTY702"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model =load_model('/content/drive/MyDrive/species/,without augument with early64(0.00001).h5')"
      ],
      "metadata": {
        "id": "eYiHGJz2Y6wh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing  data  fetching  and dataset making"
      ],
      "metadata": {
        "id": "QVaJbn56Bqgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "z4wHGGkkAamo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lGK5h8_DBo1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = test.flow_from_directory( '/content/drive/MyDrive/Colab Notebooks/dataset/test',\n",
        "              target_size = (227,227),\n",
        "              batch_size = 64,\n",
        "              class_mode = \"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ul7LvUTp_bHy",
        "outputId": "475b8f14-7460-46e5-c2ae-a95ab1bf5d28"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4000 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Accuracy"
      ],
      "metadata": {
        "id": "BbEGKs4LBkVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = model.evaluate( test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voCQnK_e2gWl",
        "outputId": "7ffaae16-4b43-4ff8-adc6-cab457c47c3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2533s 41s/step - loss: 0.0476 - accuracy: 0.9865\n"
          ]
        }
      ]
    }
  ]
}